{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import json\n",
    "import datetime as dt\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import Column, Integer, Float, String\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import Table\n",
    "from sqlalchemy import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestURL = \"https://eodhistoricaldata.com/api/eod/\"\n",
    "myEodKey = \"5ba84ea974ab42.45160048\"\n",
    "\n",
    "k = 1\n",
    "\n",
    "startDate = dt.datetime(2018,1,1) # all the data we pull\n",
    "endDate = dt.datetime(2019,1,31)\n",
    "\n",
    "model_start = dt.datetime(2018,1,1) # time range for building model\n",
    "model_end = dt.datetime(2018,12,31)\n",
    "\n",
    "backtest_start = dt.datetime(2018,12,31) # time range for backtesting\n",
    "backtest_end = dt.datetime(2019,1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_data(symbol, start=startDate, end=endDate, requestType=requestURL, apiKey=myEodKey):\n",
    "    symbolURL = str(symbol) + \".US?\"\n",
    "    startURL = \"from=\" + str(start)\n",
    "    endURL = \"to=\" + str(end)\n",
    "    apiKeyURL = \"api_token=\" + myEodKey\n",
    "    completeURL = requestURL + symbolURL + startURL + '&' + endURL + '&' + apiKeyURL + '&period=d&fmt=json'\n",
    "#     print(completeURL)\n",
    "    with urllib.request.urlopen(completeURL) as req:\n",
    "        data = json.load(req)\n",
    "        return data\n",
    "\n",
    "def clear_a_table(table_name, metadata, engine):\n",
    "    conn = engine.connect()\n",
    "    table = metadata.tables[table_name]\n",
    "    delete_st = table.delete()\n",
    "    conn.execute(delete_st)\n",
    "\n",
    "def execute_sql_statement(sql_st, engine):\n",
    "    result = engine.execute(sql_st)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pair_table(name, metadata, engine): # Create Pair1Stocks & Pair2Stocks table\n",
    "\ttables = metadata.tables.keys()            # date ranging from 2018/1/1-2019/1/31\n",
    "\tif name not in tables:\n",
    "\t\ttable = Table(name, metadata, \n",
    "\t\t\t\t\tColumn('symbol', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('date', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('open', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('high', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('low', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('close', Float, nullable=False),\n",
    "                       Column('adjusted_close', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('volume', Integer, nullable=False))\n",
    "\t\ttable.create(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairprices_table(name, metadata, engine): # Create PairPrices table only containing backtesting data\n",
    "    tables = metadata.tables.keys()                  # this table is pulled from Pair1Stocks and Pair2Stocks\n",
    "    if name not in tables:\n",
    "        table = Table(name, metadata, \n",
    "\t\t\t\t\tColumn('ticker1', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('ticker2', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('date', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('open1', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('close1', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('open2', Float, nullable=False),\n",
    "\t\t\t\t\tColumn('close2', Float, nullable=False))\n",
    "        \n",
    "        table.create(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trades_table(name, metadata, engine): # Create Trades table\n",
    "    tables = metadata.tables.keys()              # it stores PnL of every trades\n",
    "    if name not in tables:\n",
    "        table = Table(name, metadata, \n",
    "\t\t\t\t\tColumn('ticker1', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('ticker2', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('date', String(50), primary_key=True, nullable=False),\n",
    "\t\t\t\t\tColumn('profit_loss', Float, nullable=False))\n",
    "        \n",
    "        table.create(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_table(name, metadata, engine): # Create Pairs table\n",
    "    tables = metadata.tables.keys()             # it stores volatility and total PnLs of all pairs we test\n",
    "    if name not in tables:\n",
    "        table = Table(name, metadata, \n",
    "                        Column('ticker1', String(50), primary_key=True, nullable=False),\n",
    "                        Column('ticker2', String(50), primary_key=True, nullable=False),\n",
    "                        Column('volatility', Float, nullable=False),\n",
    "                        Column('profit_loss', Float, nullable=False))\n",
    "\n",
    "        table.create(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_stock_data(tickers, metadata, engine, table_name): # After creating all 5 tables\n",
    "    conn = engine.connect()                                     # pull data from website \n",
    "    table = metadata.tables[table_name]                         # and populate the Pair1Stocks and Pair2Stocks\n",
    "    for ticker in tickers:                                      # this function only runs twice\n",
    "        stock = get_daily_data(ticker)                          # once for Pair1Stocks, once for Pair2Stocks\n",
    "#         print(stock)\n",
    "        for stock_data in stock:\n",
    "            #print(k, v)\n",
    "            trading_date = stock_data['date']\n",
    "            trading_open = stock_data['open']\n",
    "            trading_high = stock_data['high']\n",
    "            trading_low = stock_data['low']\n",
    "            trading_close = stock_data['close']\n",
    "            trading_adjusted_close = stock_data['adjusted_close']\n",
    "            trading_volume = stock_data['volume']\n",
    "            insert_st = table.insert().values(symbol=ticker, date=trading_date,\n",
    "\t\t\t\t\topen = trading_open, high = trading_high, low = trading_low,\n",
    "\t\t\t\t\tclose = trading_close, adjusted_close = trading_adjusted_close, \n",
    "                       volume = trading_volume)\n",
    "            conn.execute(insert_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pair_trading_model(tickers): # building model and calculating the volatility of first pair\n",
    "    \n",
    "    s = model_start.strftime('%Y-%m-%d')\n",
    "    e = model_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    sql_st = '''\n",
    "SELECT Pair1Stocks.adjusted_close, Pair2Stocks.adjusted_close \n",
    "FROM Pair1Stocks, Pair2Stocks \n",
    "WHERE ((Pair1Stocks.date >= \\'{}\\') AND (Pair1Stocks.date <= \\'{}\\') AND (Pair1Stocks.date = Pair2Stocks.date) AND (Pair1Stocks.symbol = \\'{}\\') AND (Pair2Stocks.symbol = \\'{}\\'))\n",
    "'''.format(s, e, tickers[0], tickers[1])\n",
    "    \n",
    "    result = execute_sql_statement(sql_st, engine)\n",
    "    adj_close = np.array(result.fetchall())\n",
    "    pr = adj_close[:,0] / adj_close[:,1]\n",
    "    vol = np.std(pr)\n",
    "    \n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_pairprices_table(tickers, metadata, engine): # start preparing data for backtesting of first pair\n",
    "    conn = engine.connect()                               # pull data from Pair1Stocks and Pair2Stocks\n",
    "    table = metadata.tables['PairPrices']\n",
    "    \n",
    "    s = backtest_start.strftime('%Y-%m-%d')\n",
    "    e = backtest_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    sql_st = '''\n",
    "SELECT Pair1Stocks.symbol, Pair2Stocks.symbol, Pair1Stocks.date, Pair1Stocks.open, Pair1Stocks.close, Pair2Stocks.open, Pair2Stocks.close \n",
    "FROM Pair1Stocks, Pair2Stocks \n",
    "WHERE ((Pair1Stocks.date >= \\'{}\\') AND (Pair1Stocks.date <= \\'{}\\') AND (Pair1Stocks.date = Pair2Stocks.date) AND (Pair1Stocks.symbol = \\'{}\\') AND (Pair2Stocks.symbol = \\'{}\\'))\n",
    "''' .format(s, e, tickers[0], tickers[1])\n",
    "    \n",
    "    result = execute_sql_statement(sql_st, engine)\n",
    "    \n",
    "    for r in result:\n",
    "        insert_st = table.insert().values(ticker1=r[0], ticker2=r[1], date=r[2],\n",
    "\t\t\t\t\topen1 = r[3], close1 = r[4],\n",
    "\t\t\t\t\topen2 = r[5], close2 = r[6])\n",
    "    \n",
    "        conn.execute(insert_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesting(tickers): # backtesting every trades\n",
    "                          # and return a table of the PnL of every trade and total PnL\n",
    "    sql_st = '''\n",
    "SELECT * FROM PairPrices\n",
    "WHERE ((ticker1 = \\'{}\\') AND (ticker2 = \\'{}\\'))\n",
    "'''.format(tickers[0], tickers[1])\n",
    "    result = execute_sql_statement(sql_st, engine)\n",
    "    \n",
    "    PairPrices = pd.DataFrame(result.fetchall(), \n",
    "                columns=['ticker1', 'ticker2', 'date', 'open1', 'close1', 'open2', 'close2'])\n",
    "    \n",
    "    PnL = []\n",
    "\n",
    "    for i in range(1, len(PairPrices)):\n",
    "\n",
    "        diff = abs( PairPrices.loc[i-1, 'close1'] / PairPrices.loc[i-1, 'close2'] \\\n",
    "        - PairPrices.loc[i, 'open1'] / PairPrices.loc[i, 'open2'] )\n",
    "\n",
    "        if diff >= k*vol:\n",
    "            # short the pair\n",
    "            N1 = 10000\n",
    "            N2 = int( (-N1) * ( PairPrices.loc[i, 'open1'] / PairPrices.loc[i, 'open2'] ) )\n",
    "            # close the trade and calculate PnL\n",
    "            r = N1 * ( PairPrices.loc[i, 'open1'] - PairPrices.loc[i, 'close1'] ) \\\n",
    "                + N2 * ( PairPrices.loc[i, 'open2'] - PairPrices.loc[i, 'close2'] )\n",
    "\n",
    "        elif diff < k*vol:\n",
    "            # long the pair\n",
    "            N1 = -10000\n",
    "            N2 = int( (-N1) * ( PairPrices.loc[i, 'open1'] / PairPrices.loc[i, 'open2'] ) )\n",
    "            # close the trade and calculate PnL\n",
    "            r = N1 * ( PairPrices.loc[i, 'open1'] - PairPrices.loc[i, 'close1'] ) \\\n",
    "                + N2 * ( PairPrices.loc[i, 'open2'] - PairPrices.loc[i, 'close2'] )\n",
    "\n",
    "        PnL.append(round(r, 4))\n",
    "        \n",
    "    PnL.insert(0,0)\n",
    "    PairPrices['PnL'] = PnL\n",
    "    Trades = PairPrices.loc[:, ['ticker1', 'ticker2', 'date', 'PnL']]\n",
    "    total_PnL = round(sum(PnL), 4)\n",
    "    return Trades, total_PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_trades_table(tickers, metadata, engine): # populate the Trades table\n",
    "    conn = engine.connect()                           # with the PnL we obtain from bactesting\n",
    "    table = metadata.tables['Trades']\n",
    "    \n",
    "    for i in range(len(Trades)):\n",
    "        \n",
    "        trading_date = Trades.loc[i, 'date']\n",
    "        pnl = Trades.loc[i, 'PnL']\n",
    "        \n",
    "        insert_st = table.insert().values(ticker1=tickers[0], ticker2=tickers[1], date=trading_date,\n",
    "\t\t\t\t\tprofit_loss = pnl)\n",
    "    \n",
    "        conn.execute(insert_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_pairs_table(tickers, metadata, engine): # populate the pairs table\n",
    "    conn = engine.connect()                          # with the volatility from moedelbuilding                       \n",
    "    table = metadata.tables['Pairs']                 # and total PnL from backtesting\n",
    "                    \n",
    "    insert_st = table.insert().values(ticker1=tickers[0], ticker2=tickers[1], volatility=round(vol, 6),\n",
    "\t\t\t\tprofit_loss = total_PnL)\n",
    "    \n",
    "    conn.execute(insert_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_handler():\n",
    "    \n",
    "    tick_1, tick_2 = input('Enter a pair of stocks: ').split()\n",
    "    Date = input('Enter a date: YYYY-MM-DD: ')\n",
    "    k = float(input('Enter k: '))\n",
    "    \n",
    "    Open1D2, Close1D2 = input('Enter Open and Close Price for Stock 1: ').split()\n",
    "    Open1D2 = float(Open1D2)\n",
    "    Close1D2 = float(Close1D2)\n",
    "    \n",
    "    Open2D2, Close2D2 = input('Enter Open and Close Price for Stock 2: ').split()\n",
    "    Open2D2 = float(Open2D2)\n",
    "    Close2D2 = float(Close2D2)\n",
    "    print('------------------------------------------\\n')\n",
    "    \n",
    "    tickers = [tick_1, tick_2]\n",
    "    print('Building model of pair: {} and {}'.format(tickers[0], tickers[1]))\n",
    "    vol = build_pair_trading_model(tickers)\n",
    "    print('volatility is {}\\n'.format(round(vol, 6)))\n",
    "    print('Running Real-Time Trading Test: ')\n",
    "    \n",
    "    sql_st = '''\n",
    "SELECT Pair1Stocks.open, Pair1Stocks.close, Pair2Stocks.open, Pair2Stocks.close \n",
    "FROM Pair1Stocks, Pair2Stocks \n",
    "WHERE ((Pair1Stocks.date == \\'{}\\') AND (Pair1Stocks.date = Pair2Stocks.date) AND (Pair1Stocks.symbol = \\'{}\\') AND (Pair2Stocks.symbol = \\'{}\\'))\n",
    "''' .format(Date, tickers[0], tickers[1])\n",
    "\n",
    "    result = execute_sql_statement(sql_st, engine)\n",
    "    r = result.fetchall()\n",
    "    \n",
    "    Open1D1 = float(r[0][0])\n",
    "    Close1D1 = float(r[0][1])\n",
    "    Open2D1 = float(r[0][2])\n",
    "    Close2D1 = float(r[0][3])\n",
    "    \n",
    "    diff = abs( Close1D1 / Close2D1 - Open1D2 / Open2D2 )\n",
    "\n",
    "    if diff >= k*vol:\n",
    "        # short the pair\n",
    "        N1 = 10000\n",
    "        N2 = int( (-N1) * ( Open1D2 / Open2D2 ) )\n",
    "        # close the trade and calculate PnL\n",
    "        PnL = N1 * ( Open1D2 - Close1D2 ) + N2 * ( Open2D2 - Close2D2 )\n",
    "        print('Short {} shares of {}'.format(N1, tickers[0]))\n",
    "        print('Long {} shares of {}'.format(-N2, tickers[1]))\n",
    "\n",
    "    elif diff < k*vol:\n",
    "        # long the pair\n",
    "        N1 = -10000\n",
    "        N2 = int( (-N1) * ( Open1D2 / Open2D2 ) )\n",
    "        # close the trade and calculate PnL\n",
    "        PnL = N1 * ( Open1D2 - Close1D2 ) + N2 * ( Open2D2 - Close2D2 )\n",
    "        print('Long {} shares of {}'.format(-N1, tickers[0]))\n",
    "        print('Short {} shares of {}'.format(N2, tickers[1]))\n",
    "    \n",
    "    print('\\nPnL is {}'.format(round(PnL, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Database\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "metadata = MetaData(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all 5 tables\n",
    "create_pair_table('Pair1Stocks', metadata, engine)\n",
    "create_pair_table('Pair2Stocks', metadata, engine)\n",
    "create_pairprices_table('PairPrices', metadata, engine)\n",
    "create_trades_table('Trades', metadata, engine)\n",
    "create_pairs_table('Pairs', metadata, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the pairs\n",
    "ticker_pairs = pd.read_csv('PairTrading.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate the Pair1Stocks and Pair2Stocks tables\n",
    "pair1_list = list(set(ticker_pairs['Ticker1']))\n",
    "pair2_list = list(set(ticker_pairs['Ticker2']))\n",
    "\n",
    "populate_stock_data(pair1_list, metadata, engine, 'Pair1Stocks')\n",
    "populate_stock_data(pair2_list, metadata, engine, 'Pair2Stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model of pair: AAPL and HPQ\n",
      "volatility is 0.553129\n",
      "Running backtesting: \n",
      "Total PnL is -29696.07\n",
      "------------------------------------------\n",
      "\n",
      "Building model of pair: APC and CHK\n",
      "volatility is 2.722132\n",
      "Running backtesting: \n",
      "Total PnL is -73933.6\n",
      "------------------------------------------\n",
      "\n",
      "Building model of pair: CVX and XOM\n",
      "volatility is 0.05364\n",
      "Running backtesting: \n",
      "Total PnL is -7171.19\n",
      "------------------------------------------\n",
      "\n",
      "Building model of pair: DAL and UAL\n",
      "volatility is 0.067919\n",
      "Running backtesting: \n",
      "Total PnL is -6428.38\n",
      "------------------------------------------\n",
      "\n",
      "Building model of pair: T and VZ\n",
      "volatility is 0.07437\n",
      "Running backtesting: \n",
      "Total PnL is 16768.07\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Models and Backtesting\n",
    "for t1, t2 in zip(ticker_pairs['Ticker1'], ticker_pairs['Ticker2']):\n",
    "    tickers = [t1, t2]\n",
    "    \n",
    "    # build pair trading model\n",
    "    # return the volatility\n",
    "    print('Building model of pair: {} and {}'.format(tickers[0], tickers[1]))\n",
    "    vol = build_pair_trading_model(tickers)\n",
    "    print('volatility is {}'.format(round(vol, 6)))\n",
    "    \n",
    "    # prepare the trading data of a pair for backtesting\n",
    "    populate_pairprices_table(tickers, metadata, engine)\n",
    "    \n",
    "    # backtesting\n",
    "    # return a table of PnL of every trades and total PnL\n",
    "    print('Running backtesting: ')\n",
    "    Trades, total_PnL = backtesting(tickers)\n",
    "    print('Total PnL is {}'.format(total_PnL))\n",
    "    \n",
    "    # populate the Trades table with the Trades table from backtesting\n",
    "    populate_trades_table(tickers, metadata, engine)\n",
    "    \n",
    "    # populate the Pairs table\n",
    "    # with volatility from model building and total PnL from backtesting\n",
    "    populate_pairs_table(tickers, metadata, engine)\n",
    "    print('------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_st = 'SELECT * FROM Pairs'\n",
    "result = execute_sql_statement(sql_st, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AAPL', 'HPQ', 0.553129, -29696.07),\n",
       " ('APC', 'CHK', 2.722132, -73933.6),\n",
       " ('CVX', 'XOM', 0.05364, -7171.19),\n",
       " ('DAL', 'UAL', 0.067919, -6428.38),\n",
       " ('T', 'VZ', 0.07437, 16768.07)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trading Results of All pairs shown below\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AAPL', 'HPQ', '2018-12-31', 0.0),\n",
       " ('AAPL', 'HPQ', '2019-01-02', -16097.4),\n",
       " ('AAPL', 'HPQ', '2019-01-03', -11815.42),\n",
       " ('AAPL', 'HPQ', '2019-01-04', 13188.22),\n",
       " ('AAPL', 'HPQ', '2019-01-07', -22032.4),\n",
       " ('AAPL', 'HPQ', '2019-01-08', 12604.8),\n",
       " ('AAPL', 'HPQ', '2019-01-09', 29416.35),\n",
       " ('AAPL', 'HPQ', '2019-01-10', -12272.1),\n",
       " ('AAPL', 'HPQ', '2019-01-11', -861.61),\n",
       " ('AAPL', 'HPQ', '2019-01-14', 2305.85),\n",
       " ('AAPL', 'HPQ', '2019-01-15', 12828.55),\n",
       " ('AAPL', 'HPQ', '2019-01-16', 11293.1),\n",
       " ('AAPL', 'HPQ', '2019-01-17', -4008.84),\n",
       " ('AAPL', 'HPQ', '2019-01-18', -35556.65),\n",
       " ('AAPL', 'HPQ', '2019-01-22', -9396.5),\n",
       " ('AAPL', 'HPQ', '2019-01-23', -4459.97),\n",
       " ('AAPL', 'HPQ', '2019-01-24', -29832.64),\n",
       " ('AAPL', 'HPQ', '2019-01-25', 11461.6),\n",
       " ('AAPL', 'HPQ', '2019-01-28', -5604.75),\n",
       " ('AAPL', 'HPQ', '2019-01-29', 1252.88),\n",
       " ('AAPL', 'HPQ', '2019-01-30', 11870.78),\n",
       " ('AAPL', 'HPQ', '2019-01-31', 16020.08),\n",
       " ('APC', 'CHK', '2018-12-31', 0.0),\n",
       " ('APC', 'CHK', '2019-01-02', -22855.0),\n",
       " ('APC', 'CHK', '2019-01-03', 4367.28),\n",
       " ('APC', 'CHK', '2019-01-04', -940.72),\n",
       " ('APC', 'CHK', '2019-01-07', -9435.06),\n",
       " ('APC', 'CHK', '2019-01-08', -4900.0),\n",
       " ('APC', 'CHK', '2019-01-09', -24757.98),\n",
       " ('APC', 'CHK', '2019-01-10', 4538.9),\n",
       " ('APC', 'CHK', '2019-01-11', -7134.18),\n",
       " ('APC', 'CHK', '2019-01-14', -7472.35),\n",
       " ('APC', 'CHK', '2019-01-15', -14858.8),\n",
       " ('APC', 'CHK', '2019-01-16', -3545.81),\n",
       " ('APC', 'CHK', '2019-01-17', 8194.38),\n",
       " ('APC', 'CHK', '2019-01-18', -741.21),\n",
       " ('APC', 'CHK', '2019-01-22', 16715.84),\n",
       " ('APC', 'CHK', '2019-01-23', 1307.1),\n",
       " ('APC', 'CHK', '2019-01-24', -6846.97),\n",
       " ('APC', 'CHK', '2019-01-25', 1900.0),\n",
       " ('APC', 'CHK', '2019-01-28', -12515.4),\n",
       " ('APC', 'CHK', '2019-01-29', 1165.36),\n",
       " ('APC', 'CHK', '2019-01-30', -47.35),\n",
       " ('APC', 'CHK', '2019-01-31', 3928.37),\n",
       " ('CVX', 'XOM', '2018-12-31', 0.0),\n",
       " ('CVX', 'XOM', '2019-01-02', -3792.58),\n",
       " ('CVX', 'XOM', '2019-01-03', -2956.3),\n",
       " ('CVX', 'XOM', '2019-01-04', -18510.85),\n",
       " ('CVX', 'XOM', '2019-01-07', 7791.51),\n",
       " ('CVX', 'XOM', '2019-01-08', -8484.0),\n",
       " ('CVX', 'XOM', '2019-01-09', 8593.96),\n",
       " ('CVX', 'XOM', '2019-01-10', 9712.22),\n",
       " ('CVX', 'XOM', '2019-01-11', -2555.49),\n",
       " ('CVX', 'XOM', '2019-01-14', -2766.7),\n",
       " ('CVX', 'XOM', '2019-01-15', 5757.64),\n",
       " ('CVX', 'XOM', '2019-01-16', -3732.44),\n",
       " ('CVX', 'XOM', '2019-01-17', -2522.64),\n",
       " ('CVX', 'XOM', '2019-01-18', 8155.96),\n",
       " ('CVX', 'XOM', '2019-01-22', 13.0),\n",
       " ('CVX', 'XOM', '2019-01-23', 1180.26),\n",
       " ('CVX', 'XOM', '2019-01-24', 20115.2),\n",
       " ('CVX', 'XOM', '2019-01-25', -2860.9),\n",
       " ('CVX', 'XOM', '2019-01-28', -866.54),\n",
       " ('CVX', 'XOM', '2019-01-29', -9004.84),\n",
       " ('CVX', 'XOM', '2019-01-30', -3353.08),\n",
       " ('CVX', 'XOM', '2019-01-31', -7084.58),\n",
       " ('DAL', 'UAL', '2018-12-31', 0.0),\n",
       " ('DAL', 'UAL', '2019-01-02', -6609.72),\n",
       " ('DAL', 'UAL', '2019-01-03', -10007.24),\n",
       " ('DAL', 'UAL', '2019-01-04', 3880.6),\n",
       " ('DAL', 'UAL', '2019-01-07', -5336.58),\n",
       " ('DAL', 'UAL', '2019-01-08', -4746.52),\n",
       " ('DAL', 'UAL', '2019-01-09', -968.94),\n",
       " ('DAL', 'UAL', '2019-01-10', 16799.52),\n",
       " ('DAL', 'UAL', '2019-01-11', 7045.36),\n",
       " ('DAL', 'UAL', '2019-01-14', -1980.0),\n",
       " ('DAL', 'UAL', '2019-01-15', -5030.72),\n",
       " ('DAL', 'UAL', '2019-01-16', -11141.79),\n",
       " ('DAL', 'UAL', '2019-01-17', 7307.34),\n",
       " ('DAL', 'UAL', '2019-01-18', 3350.55),\n",
       " ('DAL', 'UAL', '2019-01-22', 1924.84),\n",
       " ('DAL', 'UAL', '2019-01-23', 4732.18),\n",
       " ('DAL', 'UAL', '2019-01-24', -4715.83),\n",
       " ('DAL', 'UAL', '2019-01-25', 3550.0),\n",
       " ('DAL', 'UAL', '2019-01-28', -2353.86),\n",
       " ('DAL', 'UAL', '2019-01-29', -7443.55),\n",
       " ('DAL', 'UAL', '2019-01-30', 10057.76),\n",
       " ('DAL', 'UAL', '2019-01-31', -4741.78),\n",
       " ('T', 'VZ', '2018-12-31', 0.0),\n",
       " ('T', 'VZ', '2019-01-02', 11110.36),\n",
       " ('T', 'VZ', '2019-01-03', 1019.44),\n",
       " ('T', 'VZ', '2019-01-04', 4489.39),\n",
       " ('T', 'VZ', '2019-01-07', 1816.56),\n",
       " ('T', 'VZ', '2019-01-08', -6368.37),\n",
       " ('T', 'VZ', '2019-01-09', -4427.61),\n",
       " ('T', 'VZ', '2019-01-10', 1874.05),\n",
       " ('T', 'VZ', '2019-01-11', 3754.1),\n",
       " ('T', 'VZ', '2019-01-14', -1861.6),\n",
       " ('T', 'VZ', '2019-01-15', -1102.6),\n",
       " ('T', 'VZ', '2019-01-16', 4779.5),\n",
       " ('T', 'VZ', '2019-01-17', 2663.52),\n",
       " ('T', 'VZ', '2019-01-18', 479.62),\n",
       " ('T', 'VZ', '2019-01-22', -2103.52),\n",
       " ('T', 'VZ', '2019-01-23', -2504.98),\n",
       " ('T', 'VZ', '2019-01-24', 1084.68),\n",
       " ('T', 'VZ', '2019-01-25', 3984.7),\n",
       " ('T', 'VZ', '2019-01-28', 6228.8),\n",
       " ('T', 'VZ', '2019-01-29', 2741.4),\n",
       " ('T', 'VZ', '2019-01-30', -10977.8),\n",
       " ('T', 'VZ', '2019-01-31', 88.43)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_st = 'SELECT * FROM Trades'\n",
    "result = execute_sql_statement(sql_st, engine)\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a pair of stocks: AAPL HPQ\n",
      "Enter a date: YYYY-MM-DD: 2019-01-15\n",
      "Enter k: 11.3\n",
      "Enter Open and Close Price for Stock 1: 23.4 33.2\n",
      "Enter Open and Close Price for Stock 2: 12.3 45.6\n",
      "------------------------------------------\n",
      "\n",
      "Building model of pair: AAPL and HPQ\n",
      "volatility is 0.553129\n",
      "\n",
      "Running Real-Time Trading Test: \n",
      "Long 10000 shares of AAPL\n",
      "Short 19024 shares of HPQ\n",
      "\n",
      "PnL is -535499.2\n"
     ]
    }
   ],
   "source": [
    "# manually real-time trading test\n",
    "manual_handler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
